# -*- coding: utf-8 -*-
"""stock_prediction-RL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WtBwNAsb4b8szc404CctwhQTBLEeyy32
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_ver.sion 1.x

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
import pandas as pd
import seaborn as sns
from pylab import rcParams
import matplotlib.pyplot as plt
from matplotlib import rc
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.layers import Bidirectional, Dropout, Activation, Dense, LSTM
from tensorflow.python.keras.layers import CuDNNLSTM
from tensorflow.keras.models import Sequential
import seaborn as sns
import sys

# %matplotlib inline

sns.set(style='whitegrid', palette='muted', font_scale=1.5)

rcParams['figure.figsize'] = 14, 8

RANDOM_SEED = 42

np.random.seed(RANDOM_SEED)

# Data comes from:
# https://finance.yahoo.com/quote/BTC-USD/history?period1=1279314000&period2=1556053200&interval=1d&filter=history&frequency=1d

csv_path = "BTC_USD_1D.csv"
# csv_path = "https://raw.githubusercontent.com/curiousily/Deep-Learning-For-Hackers/master/data/3.stock-prediction/AAPL.csv"

df = pd.read_csv(csv_path)
df = df.drop(columns=['Unnamed: 0', 'symbol', 'time'], axis=1)

df.head()

df.tail()

df.shape

plt.plot(df['close'].head())
plt.plot(df['open'].head())

"""# Normalization"""

close_price = df['close']
open_price = df['open']
high_price = df['high']
low_price = df['low']
vol_price = df['volume']

scaler = MinMaxScaler()

close_price = df.close.values.reshape(-1, 1)
open_price = df.open.values.reshape(-1, 1)

scaled_close = scaler.fit_transform(close_price)
scaled_open = scaler.fit_transform(open_price)

scaled_close.shape, scaled_open.shape

np.isnan(scaled_close).any()
np.isnan(scaled_open).any()

scaled_close = scaled_close[~np.isnan(scaled_close)]
scaled_open = scaled_open[~np.isnan(scaled_open)]

scaled_close = scaled_close.reshape(-1, 1)
scaled_open = scaled_open.reshape(-1, 1)

np.isnan(scaled_close).any(), np.isnan(scaled_open).any()

"""# Preprocessing"""

SEQ_LEN = 100

def to_sequences(data, seq_len):
    d = []

    for index in range(len(data) - seq_len):
        d.append(data[index: index + seq_len])

    return np.array(d)

def preprocess(data_raw, seq_len, train_split):

    data = to_sequences(data_raw, seq_len)

    num_train = int(train_split * data.shape[0])

    X_train = data[:num_train, :-1, :]
    y_train = data[:num_train, -1, :]

    X_test = data[num_train:, :-1, :]
    y_test = data[num_train:, -1, :]

    return X_train, y_train, X_test, y_test


X_train_close, y_train_close, X_test_close, y_test_close = preprocess(scaled_close, SEQ_LEN, train_split = 0.95)
X_train_open, y_train_open, X_test_open, y_test_open = preprocess(scaled_open, SEQ_LEN, train_split = 0.95)

X_train_open.shape, X_train_close.shape

X_test_close.shape, X_test_open.shape

"""# Model"""

def train_model(X_train, X_test, y_train, y_test):
    DROPOUT = 0.2
    WINDOW_SIZE = SEQ_LEN - 1

    model = keras.Sequential()

    model.add(Bidirectional(CuDNNLSTM(WINDOW_SIZE, return_sequences=True),
                            input_shape=(WINDOW_SIZE, X_train.shape[-1])))
    model.add(Dropout(rate=DROPOUT))

    model.add(Bidirectional(CuDNNLSTM((WINDOW_SIZE * 2), return_sequences=True)))
    model.add(Dropout(rate=DROPOUT))

    model.add(Bidirectional(CuDNNLSTM(WINDOW_SIZE, return_sequences=False)))

    model.add(Dense(units=1))

    model.add(Activation('linear'))
    model.compile(
        loss='mean_squared_error',
        optimizer='adam'
    )
    BATCH_SIZE = 64

    history = model.fit(
        X_train,
        y_train,
        epochs=50,
        batch_size=BATCH_SIZE,
        shuffle=False,
        validation_split=0.1
    )
    model.evaluate(X_test, y_test)
    results = model.predict(X_test)
    y_hat = model.predict(X_test)

    y_test_inverse = scaler.inverse_transform(y_test)
    y_hat_inverse = scaler.inverse_transform(y_hat)

    plt.plot(y_test_inverse, label="Actual Price", color='green')
    plt.plot(y_hat_inverse, label="Predicted Price", color='red')

    plt.title('Bitcoin price prediction')
    plt.xlabel('Time [days]')
    plt.ylabel('Price')
    plt.legend(loc='best')

    plt.show()
    return model

close_model = train_model(X_train_close, X_test_close, y_train_close, y_test_close)

open_model = train_model(X_train_open, X_test_open, y_train_open, y_test_open)

price_mean = df['open'] + df['close'] / 2

price_mean = np.array(price_mean.tolist())
price_mean_1 = price_mean[:-1]
price_mean_2 = price_mean[1:]
price_diff = price_mean_2 - price_mean_1

np.min(price_mean), np.max(price_mean)

min(df['open']), min(df['close'])

sns.histplot(price_diff, bins=100,).set_title('bitcoin price fluctuation distribution')

sns.histplot(price_mean, bins=100).set_title('bitcoin price distribution')

price_mean_bins = np.linspace(min(price_mean), max(price_mean), 100)
price_mean_bins = np.append(price_mean_bins, np.inf)

price_diff_bins = np.linspace(-800, 800, 110)
price_diff_bins = np.append(price_diff_bins, np.inf)
price_diff_bins = np.insert(price_diff_bins, 55, 0)

def get_state(price, fluc):
  for i in range(len(price_mean_bins)):
    if price < price_mean_bins[i]:
      break
  for j in range(len(price_diff_bins)):
    if fluc < price_diff_bins[j]:
      break
  return (i, j)

class Environment():
  def __init__(self, price_mean):
    self.price_mean = price_mean
    self.day = 0
    self.nA = 9

  def get_day(self):
    return self.day

  def get_date_price(self, day):
    if day <= 0:
      return self.price_mean[0]
    return self.price_mean[day]

  def get_reward(self, bitcoin):
    reward = 0
    # if (bitcoin <= 0.01 and self.day > 1000) or (bitcoin < 0.1 and self.day > 1000):
    #   reward -= 10
    reward += bitcoin * (self.get_date_price(self.day) - self.get_date_price(self.day - 1))
    return reward

  def step(self, bitcoin):
    self.day += 1
    return self.get_reward(bitcoin)

  def reset(self):
    self.day = 0

env = Environment(price_mean)

def find_tomorrow_price(prices):
  prices = prices[-99:]
  prices = np.expand_dims(prices, (1))
  prices = scaler.transform(prices)
  pricesT = np.zeros(shape = (1, 99, 1))
  pricesT[0] = prices
  tomorrow_price = open_model.predict(pricesT)
  tomorrow_price = scaler.inverse_transform(tomorrow_price)[0, 0]
  return tomorrow_price

def e_greedy(s, q):
    p = [epsilon / env.nA for a in range(env.nA)]
    p[np.argmax(q[s])] += 1 - epsilon
    action = np.random.choice(range(env.nA), p=p)
    return action, p
def get_fluc(today, prices, trainable):
  flucs = []
  if trainable:
    for i in range(-2, 0):
      flucs.append(env.get_date_price(today + i + 1) - env.get_date_price(today + i))
  else:
    tomorrow_price = find_tomorrow_price(prices)
    for i in range(-1, 0):
      flucs.append(env.get_date_price(today + i + 1) - env.get_date_price(today + i))
    flucs.append(tomorrow_price - env.get_date_price(today))
  return np.mean(flucs)

discount_factor = 1
starting_alpha = .01
alpha = starting_alpha
starting_epsilon = .01
epsilon = starting_epsilon
q1 = np.zeros(shape=(len(price_mean_bins), len(price_diff_bins), 9))
q2 = np.zeros(shape=(len(price_mean_bins), len(price_diff_bins), 9))
double_qlearning_rewards = []
num_episodes = 400
for i in range(num_episodes):
    prices = []
    episode_rewards = 0
    env.reset()
    fluc = get_fluc(env.get_day(), None, True)
    s = get_state(env.get_date_price(env.get_day()), fluc)
    while True:
        prices.append(env.get_date_price(env.get_day()))
        totalQ = q1 + q2
        a, probs = e_greedy(s, totalQ)
        r = env.step(a)
        if len(prices) >= 99:
          fluc = get_fluc(env.get_day(), prices, False)
        else:
          fluc = get_fluc(env.get_day(), None, True)
        next_s = get_state(env.get_date_price(env.get_day()), fluc)

        episode_rewards += r
        if np.random.rand() < .5:
            q1[s][a] += alpha*(r + discount_factor*q2[next_s][np.argmax(q1[next_s])] - q1[s][a])
        else:
            q2[s][a] += alpha*(r + discount_factor*q1[next_s][np.argmax(q2[next_s])] - q2[s][a])
        s = next_s
        if env.get_day() == 2500:
            double_qlearning_rewards.append(episode_rewards)
            break
    if (i + 1)%5 == 0:
        epsilon -= starting_epsilon / 90
        alpha -= starting_alpha / 90
        print("\rEpisode {}/{}.".format(i + 1, num_episodes), end="")
        sys.stdout.flush()

sns.lineplot(data=double_qlearning_rewards)
plt.annotate(str(np.round(max(double_qlearning_rewards))), (1020, max(double_qlearning_rewards)))

fig = plt.figure()
ax = plt.axes(projection="3d")

z_points = 15 * np.random.random(100)
x_points = np.cos(z_points) + 0.1 * np.random.randn(100)
y_points = np.sin(z_points) + 0.1 * np.random.randn(100)
ax.scatter3D(x_points, y_points, z_points, c=z_points, cmap='hsv');

plt.show()

totalQ.shape

x,y,z = totalQ.nonzero()

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
fig = plt.figure(figsize=(15, 10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(-x, y, z, zdir='z', cmap='Blues')
ax.set_ylabel('price means')
ax.set_xlabel('price diffs')
ax.set_zlabel('actions')
ax.set_xticks([])
ax.set_yticks([])
ax.set_zticks([])
plt.show()

